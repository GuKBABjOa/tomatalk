from fastapi import WebSocket
from sqlalchemy.ext.asyncio import AsyncSession
from fastapi import WebSocket, Depends
from sqlalchemy.ext.asyncio import AsyncSession
from database import get_async_db
from transcripts.repository.repository import save_statement
from ai.utils.summation import generate_summary
from transcripts.repository.repository import save_summation
from pydub import AudioSegment
import whisper
import numpy as np
import torch
import json

SAMPLE_RATE = 16000

# âœ… Whisper ëª¨ë¸ ë¡œë“œ (medium ì´ìƒ ê¶Œì¥)
device = "cuda" if torch.cuda.is_available() else "cpu"
model = whisper.load_model("medium", device="cpu")

async def audio_transcription(websocket: WebSocket, db: AsyncSession):
    """
    ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ìˆ˜ì‹ í•˜ê³  Whisper ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” WebSocket í•¸ë“¤ëŸ¬
    """
    await websocket.accept()
    print("âœ… WebSocket ì—°ê²°ë¨!")

    metadata = await websocket.receive_text()
    metadata = json.loads(metadata)
    debate_id = metadata.get("debate_id", "unknown")
    position = metadata.get("position", "unknown")
    user_id = metadata.get("user_id", "unknown")
    nickname = metadata.get("nickname", "unknown")
    round = metadata.get("round", 0)
    print(f"ğŸ“Œ ë°©: {debate_id}, ì£¼ì œ: {position} / ë°œì–¸ì: {nickname} / ë¼ìš´ë“œ: {round}")

    # âœ… WebSocket ì„¸ì…˜ë³„ ê°œë³„ ìƒíƒœ ë³€ìˆ˜ (ì „ì—­ ë³€ìˆ˜ ì œê±°)
    audio_buffer = []
    statement = ""

    try:
        while True:
            data = await websocket.receive_bytes()
            if not data:
                print("âš  ìˆ˜ì‹ ëœ ë°ì´í„° ì—†ìŒ.")
                break  

            # PCM ë°ì´í„°ë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜
            audio_chunk = np.frombuffer(data, dtype=np.int16)
            audio_buffer.append(audio_chunk)

            # 20ì´ˆ ë¶„ëŸ‰ì˜ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ìŒ“ì´ë©´ ë³€í™˜ ì‹¤í–‰
            if len(audio_buffer) * 4096 / 160000 > 20:
                text = await process_audio(audio_buffer, websocket)
                if text:
                    statement += text  # âœ… WebSocket ì—°ê²°ë³„ statement ìœ ì§€
                audio_buffer = []
    except Exception as e:
        print(f"ì˜¤ë””ì˜¤ ë³€í™˜ ì˜¤ë¥˜: {e}")
    finally:
        print("ğŸ”´ WebSocket ì—°ê²°ì´ ëŠì–´ì¡ŒìŠµë‹ˆë‹¤. ë³€í™˜ëœ ë°œì–¸ ì €ì¥ì„ ì‹œë„í•©ë‹ˆë‹¤...")
        await save_statement(db, debate_id, position, user_id, nickname, round, statement)  # âœ… ê°œë³„ statement ì €ì¥
        response = await generate_summary(statement)  # âœ… ê°œë³„ summary ì €ì¥
        await save_summation(db, debate_id, position, user_id, nickname, round, response)  # âœ… ê°œë³„ summary ì €ì¥
        await close_websocket_safely(websocket)


async def process_audio(audio_buffer, websocket):
    """
    ì˜¤ë””ì˜¤ ë²„í¼ë¥¼ ì²˜ë¦¬í•˜ê³  Whisper ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
    """
    if not audio_buffer:
        return ""

    try:
        # PCM ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ NumPy ë°°ì—´ë¡œ ë³€í™˜
        audio_data = np.concatenate(audio_buffer, axis=0)
    except ValueError:
        print("ë²„í¼ ì¡°í•© ì˜¤ë¥˜: ë°ì´í„°ê°€ ì†ìƒë¨")
        return ""

    # âœ… NaN ë° Inf ê°’ ì œê±°
    audio_data = np.nan_to_num(audio_data, nan=0.0, posinf=1.0, neginf=-1.0)

    # âœ… ì˜¤ë²„í”Œë¡œìš° ë°©ì§€ (16-bit PCM ë³€í™˜)
    audio_data = np.clip(audio_data, -32768, 32767).astype(np.int16)

    # âœ… ê³µë°± ë°ì´í„° í•„í„°ë§
    if np.abs(audio_data).mean() < 100:
        print("âš  ì¡ìŒ ë˜ëŠ” ê³µë°± ë°ì´í„° ê°ì§€, ë³€í™˜ ìƒëµ")
        return ""

    if len(audio_data) < SAMPLE_RATE:  # 1ì´ˆ ì´í•˜ ë°ì´í„° ë¬´ì‹œ
        return ""

    # âœ… PCM ë°ì´í„°ë¥¼ Whisperê°€ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” `numpy` ë°°ì—´ë¡œ ë³€í™˜
    whisper_input = pcm_to_numpy(audio_data.tobytes(), SAMPLE_RATE)

    # âœ… Whisper ëª¨ë¸ë¡œ ë³€í™˜ ì‹¤í–‰
    try:
        result = model.transcribe(
            whisper_input,
            language="ko",
            temperature=0.2,
            no_speech_threshold=0.3,
            fp16=False
        )
        text = result["text"].strip()
        if text:
            print(f"ë³€í™˜ëœ í…ìŠ¤íŠ¸: {text}")
            await websocket.send_json({"transcription": text})
        return text
    except Exception as e:
        print(f"Whisper ë³€í™˜ ì˜¤ë¥˜: {e}")
        return ""

# PCM ë°ì´í„°ë¥¼ Whisperê°€ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” `numpy` ë°°ì—´ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def pcm_to_numpy(pcm_data, sample_rate=16000):
    """
    PCM ë°ì´í„°ë¥¼ Whisper ëª¨ë¸ì— ì§ì ‘ ì…ë ¥í•  ìˆ˜ ìˆëŠ” `numpy` ë°°ì—´ë¡œ ë³€í™˜
    """
    audio_segment = AudioSegment(
        data=pcm_data,
        sample_width=2,  # 16-bit PCM
        frame_rate=sample_rate,
        channels=1
    )

    samples = np.array(audio_segment.get_array_of_samples()).astype(np.float32) / 32768.0

    # Whisperê°€ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ê³ ì • ê¸¸ì´ ìœ ì§€ (10ì´ˆ)
    target_length = sample_rate * 10  # 10ì´ˆ
    if len(samples) < target_length:
        padded_samples = np.zeros(target_length, dtype=np.float32)
        padded_samples[:len(samples)] = samples
        samples = padded_samples
    else:
        samples = samples[:target_length]

    return whisper.pad_or_trim(samples)  # Whisperì— ì ì ˆí•œ ê¸¸ì´ ë§ì¶¤

async def close_websocket_safely(websocket):
    """
    WebSocketì´ ì¢…ë£Œë  ë•Œ ì•ˆì „í•˜ê²Œ ë‹«ê³  ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜
    """
    try:
        if websocket.client_state in ["CONNECTED", "CONNECTING"]:
            print("âœ… WebSocket ì •ìƒ ì¢…ë£Œ ì¤‘...")
            await websocket.close(code=1000, reason="Normal Closure")
            print("âœ… WebSocketì´ ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print("âš  WebSocketì´ ì´ë¯¸ ì¢…ë£Œëœ ìƒíƒœì…ë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ WebSocket ë‹«ê¸° ì˜¤ë¥˜ ë°œìƒ: {e}")
