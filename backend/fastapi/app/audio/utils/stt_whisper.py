from fastapi import WebSocket, UploadFile
from sqlalchemy.ext.asyncio import AsyncSession
from fastapi import WebSocket, Depends
from sqlalchemy.ext.asyncio import AsyncSession
from fastapi import WebSocket, Depends
from sqlalchemy.ext.asyncio import AsyncSession
from database import get_async_db
from transcripts.repository.repository import save_statement, save_summation, save_basic_practice
from audio.utils.basic_topic import get_basic_topic
from audio.utils.basic_step import get_question
from ai.utils.summation import generate_summary
from analytics.utils.analytics import speech_rate
from pydub import AudioSegment
import soundfile as sf
import time 
import whisper
import numpy as np
import torch
import io
import librosa

SAMPLE_RATE = 16000

# âœ… Whisper ëª¨ë¸ ë¡œë“œ (medium ì´ìƒ ê¶Œì¥)
device = "cuda" if torch.cuda.is_available() else "cpu"
model = whisper.load_model("medium", device=device)

async def audio_transcription(websocket: WebSocket, db: AsyncSession):
    """
    ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ìˆ˜ì‹ í•˜ê³  Whisper ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” WebSocket í•¸ë“¤ëŸ¬
    """
    await websocket.accept()
    print("âœ… WebSocket ì—°ê²°ë¨!")
    start_time = time.time

    # âœ… WebSocket ì„¸ì…˜ë³„ ê°œë³„ ìƒíƒœ ë³€ìˆ˜ (ì „ì—­ ë³€ìˆ˜ ì œê±°)
    audio_buffer = []
    statement = ""

    try:
        while True:
            data = await websocket.receive_bytes()
            if not data:
                print("âš  ìˆ˜ì‹ ëœ ë°ì´í„° ì—†ìŒ.")
                break  


            # PCM ë°ì´í„°ë¥¼ NumPy ë°°ì—´ë¡œ ë³€í™˜
            audio_chunk = np.frombuffer(data, dtype=np.int16)
            audio_buffer.append(audio_chunk)

            # 20ì´ˆ ë¶„ëŸ‰ì˜ ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ìŒ“ì´ë©´ ë³€í™˜ ì‹¤í–‰
            if len(audio_buffer) * 4096 / 160000 > 200:
                text = await process_audio(audio_buffer, websocket)
                if text:
                    statement += text  # âœ… WebSocket ì—°ê²°ë³„ statement ìœ ì§€
                audio_buffer = []
    except Exception as e:
        print(f"ì˜¤ë””ì˜¤ ë³€í™˜ ì˜¤ë¥˜: {e}")
    finally:
        print("ğŸ”´ WebSocket ì—°ê²°ì´ ëŠì–´ì¡ŒìŠµë‹ˆë‹¤. ë³€í™˜ëœ ë°œì–¸ ì €ì¥ì„ ì‹œë„í•©ë‹ˆë‹¤...")
        # await save_statement(db, debate_id, position, user_id, nickname, round, statement)  # âœ… ê°œë³„ statement ì €ì¥
        # elapsed_time = time.time - start_time 
        # await speech_rate(db, user_id, elapsed_time, statement)
        # response = await generate_summary(statement)  # âœ… ê°œë³„ summary ì €ì¥
        # await save_summation(db, debate_id, position, user_id, nickname, round, response)  # âœ… ê°œë³„ summary ì €ì¥
        await close_websocket_safely(websocket)

async def audio_transcription_practice(
        websocket: WebSocket,
        db: AsyncSession,
        topic_id: int,
        stance: str, 
        step: int,
        user_id: int):
    """
    ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ìˆ˜ì‹ í•˜ê³  Whisper ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” WebSocket í•¸ë“¤ëŸ¬
    """
    await websocket.accept()
    print("âœ… WebSocket ì—°ê²°ë¨!")

    # âœ… WebSocket ì„¸ì…˜ë³„ ê°œë³„ ìƒíƒœ ë³€ìˆ˜ (ì „ì—­ ë³€ìˆ˜ ì œê±°)
    audio_buffer = []
    statement = ""

    try:
        while True:
            data = await websocket.receive_bytes()
            if not data:
                print("âš  ìˆ˜ì‹ ëœ ë°ì´í„° ì—†ìŒ.")
                break  

            audio_chunk = np.frombuffer(data, dtype=np.int16)
            audio_buffer.append(audio_chunk)

            if len(audio_buffer) * 4096 / 160000 > 20:
                text = await process_audio(audio_buffer, websocket)
                if text:
                    statement += text  
                audio_buffer = []

    except Exception as e:
        print(f"âŒ ì˜¤ë””ì˜¤ ë³€í™˜ ì˜¤ë¥˜: {e}")
    finally:
        print("ğŸ”´ WebSocket ì—°ê²° ì¢…ë£Œ ì²˜ë¦¬ ì¤‘...")
        topic = await get_basic_topic(topic_id)
        question = await get_question(step)
        await save_basic_practice(
            db= db,
            topic= topic,
            position= stance,
            question=question,
            user_id= user_id,
            statement= statement)  # âœ… ê°œë³„ statement ì €ì¥
        try:
            await websocket.close()
            print("âœ… WebSocket ì •ìƒ ì¢…ë£Œ")
        except Exception as e:
            print(f"âŒ WebSocket ì¢…ë£Œ ì˜¤ë¥˜ ë°œìƒ: {e}")

async def process_audio(audio_buffer, websocket):
    """
    ì˜¤ë””ì˜¤ ë²„í¼ë¥¼ ì²˜ë¦¬í•˜ê³  Whisper ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
    """
    if not audio_buffer:
        return ""

    try:
        # PCM ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ NumPy ë°°ì—´ë¡œ ë³€í™˜
        audio_data = np.concatenate(audio_buffer, axis=0)
    except ValueError:
        print("ë²„í¼ ì¡°í•© ì˜¤ë¥˜: ë°ì´í„°ê°€ ì†ìƒë¨")
        return ""

    # âœ… NaN ë° Inf ê°’ ì œê±°
    audio_data = np.nan_to_num(audio_data, nan=0.0, posinf=1.0, neginf=-1.0)

    # âœ… ì˜¤ë²„í”Œë¡œìš° ë°©ì§€ (16-bit PCM ë³€í™˜)
    audio_data = np.clip(audio_data, -32768, 32767).astype(np.int16)

    # âœ… ê³µë°± ë°ì´í„° í•„í„°ë§
    if np.abs(audio_data).mean() < 100:
        print("âš  ì¡ìŒ ë˜ëŠ” ê³µë°± ë°ì´í„° ê°ì§€, ë³€í™˜ ìƒëµ")
        return ""

    if len(audio_data) < SAMPLE_RATE:  # 1ì´ˆ ì´í•˜ ë°ì´í„° ë¬´ì‹œ
        return ""

    # âœ… PCM ë°ì´í„°ë¥¼ Whisperê°€ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” `numpy` ë°°ì—´ë¡œ ë³€í™˜
    whisper_input = pcm_to_numpy(audio_data.tobytes(), SAMPLE_RATE)

    # âœ… Whisper ëª¨ë¸ë¡œ ë³€í™˜ ì‹¤í–‰
    try:
        result = model.transcribe(
            whisper_input,
            language="ko",
            temperature=0.2,
            no_speech_threshold=0.5,
            fp16=False
        )
        text = result["text"].strip()
        if text:
            print(f"ë³€í™˜ëœ í…ìŠ¤íŠ¸: {text}")
            await websocket.send_json({"transcription": text})
        return text
    except Exception as e:
        print(f"Whisper ë³€í™˜ ì˜¤ë¥˜: {e}")
        return ""

# PCM ë°ì´í„°ë¥¼ Whisperê°€ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” `numpy` ë°°ì—´ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def pcm_to_numpy(pcm_data, sample_rate=16000):
    """
    PCM ë°ì´í„°ë¥¼ Whisper ëª¨ë¸ì— ì§ì ‘ ì…ë ¥í•  ìˆ˜ ìˆëŠ” `numpy` ë°°ì—´ë¡œ ë³€í™˜
    """
    audio_segment = AudioSegment(
        data=pcm_data,
        sample_width=2,  # 16-bit PCM
        frame_rate=sample_rate,
        channels=1
    )

    samples = np.array(audio_segment.get_array_of_samples()).astype(np.float32) / 32768.0

    # Whisperê°€ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ê³ ì • ê¸¸ì´ ìœ ì§€ (10ì´ˆ)
    target_length = sample_rate * 10  # 10ì´ˆ
    if len(samples) < target_length:
        padded_samples = np.zeros(target_length, dtype=np.float32)
        padded_samples[:len(samples)] = samples
        samples = padded_samples
    else:
        samples = samples[:target_length]

    return whisper.pad_or_trim(samples)  # Whisperì— ì ì ˆí•œ ê¸¸ì´ ë§ì¶¤

async def close_websocket_safely(websocket):
    """
    WebSocketì´ ì¢…ë£Œë  ë•Œ ì•ˆì „í•˜ê²Œ ë‹«ê³  ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜
    """
    try:
        if websocket.client_state in ["CONNECTED", "CONNECTING"]:
            print("âœ… WebSocket ì •ìƒ ì¢…ë£Œ ì¤‘...")
            await websocket.close(code=1000, reason="Normal Closure")
            print("âœ… WebSocketì´ ì •ìƒì ìœ¼ë¡œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print("âš  WebSocketì´ ì´ë¯¸ ì¢…ë£Œëœ ìƒíƒœì…ë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ WebSocket ë‹«ê¸° ì˜¤ë¥˜ ë°œìƒ: {e}")


async def stt_file(file: UploadFile, topic: str, position: str, question: str, user_id: int, db: AsyncSession):
    """
    WAV íŒŒì¼ì„ ë°›ì•„ Whisper STT ë³€í™˜ì„ ì‹¤í–‰í•˜ê³ , ë³€í™˜ëœ í…ìŠ¤íŠ¸ë¥¼ DBì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜.

    Args:
        file (UploadFile): ì—…ë¡œë“œëœ WAV íŒŒì¼
        topic (str): í† ë¡  ì£¼ì œ
        position (str): ì°¬ì„±/ë°˜ëŒ€ ì—¬ë¶€
        question (str): ì§ˆë¬¸ ë‚´ìš©
        user_id (int): ì‚¬ìš©ì ID
        db (AsyncSession): ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜

    Returns:
        dict: ë³€í™˜ëœ í…ìŠ¤íŠ¸ ë°ì´í„° ë°˜í™˜
    """
    try:
        print(f"ğŸ”¥ STT ë³€í™˜ ì‹œì‘ (GPU ì‚¬ìš©: {device == 'cuda'})")

        # âœ… ì—…ë¡œë“œëœ íŒŒì¼ì„ ë°”ë¡œ ë©”ëª¨ë¦¬ì—ì„œ ì½ê¸°
        audio_bytes = await file.read()
        audio_data, sample_rate = sf.read(io.BytesIO(audio_bytes), dtype="float32")

        # âœ… ìƒ˜í”Œë§ ì†ë„ë¥¼ 16kHzë¡œ ë³€í™˜ (í•„ìˆ˜)
        if sample_rate != 16000:
            print(f"âš ï¸ ì…ë ¥ ìƒ˜í”Œë§ ì†ë„: {sample_rate}Hz â†’ 16kHz ë³€í™˜ í•„ìš”")
            audio_data = librosa.resample(audio_data, orig_sr=sample_rate, target_sr=16000)

        # âœ… Whisper ë³€í™˜ ì‹¤í–‰
        result = model.transcribe(audio_data, language="ko", fp16=False)
        text = result["text"].strip()

        # âœ… ë³€í™˜ëœ í…ìŠ¤íŠ¸ ì €ì¥
        await save_basic_practice(
            db=db,
            topic=topic,
            position=position,
            question=question,
            user_id=user_id,
            statement=text
        )

        return {"message": "STT ë³€í™˜ ë° ì €ì¥ ì™„ë£Œ", "transcription": text}

    except Exception as e:
        print(f"âŒ STT ë³€í™˜ ì˜¤ë¥˜: {e}")
        return {"error": "ìŒì„± ë³€í™˜ ì‹¤íŒ¨"}
